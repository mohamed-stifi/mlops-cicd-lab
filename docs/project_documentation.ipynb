{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"13GbqXYBZsF09DqtLLFWqHRQJp1SZHook","authorship_tag":"ABX9TyMNxgZOwRVgWNGVJVXoQFPS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"K7OyzTVfW9fk","executionInfo":{"status":"ok","timestamp":1764538820302,"user_tz":-60,"elapsed":1344,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"352cff47-555e-4d36-cdfe-aae7c3db6a10"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Books To Read/ML Engineering Notebook+Docs'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["import os\n","os.chdir(\"/content/drive/MyDrive/Books To Read/ML Engineering Notebook+Docs\")\n","\n","%pwd"]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A-n49xAQXUdB","executionInfo":{"status":"ok","timestamp":1764538823026,"user_tz":-60,"elapsed":107,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"667abd4d-1063-4457-b974-6291895a19c0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["'CI Cd with github actions for MLops.ipynb'   mlops-cicd-lab\n","'MLflow tutorial doc.ipynb'\n"]}]},{"cell_type":"markdown","source":["# **The MLOps Project Structure & Unit Testing**\n","\n","1. **The Standard MLOps Directory Structure**\n","```text\n","my-mlops-project/\n","├── .github/              # Where GitHub Actions live (we will touch this later)\n","├── data/                 # Local data (gitignored!)\n","├── src/                  # Source code (The \"Software\")\n","│   ├── __init__.py\n","│   ├── preprocessing.py  # Functions to clean data\n","│   ├── train.py          # Functions to train models\n","│   └── predict.py        # Inference logic\n","├── tests/                # Automated tests\n","│   ├── __init__.py\n","│   └── test_preprocessing.py\n","├── requirements.txt      # Dependencies\n","└── README.md\n","```\n","\n","**Step 1: Setup and Your First Test**\n","-\n","Create a new folder `mlops-cicd-lab` and set up the structure:"],"metadata":{"id":"6XUV_uz4X56C"}},{"cell_type":"code","source":["!mkdir mlops-cicd-lab\n","\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zQipN3sqXYVf","executionInfo":{"status":"ok","timestamp":1764517610362,"user_tz":-60,"elapsed":181,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"6d5e2e56-6f75-4dea-9ac3-7a617be7ed50"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘mlops-cicd-lab’: File exists\n","'MLflow tutorial doc.ipynb'   mlops-cicd-lab   Untitled0.ipynb\n"]}]},{"cell_type":"code","source":["os.chdir(\"mlops-cicd-lab\")\n","%pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"o6mKI2y9XhGa","executionInfo":{"status":"ok","timestamp":1764538841556,"user_tz":-60,"elapsed":18,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"c7d7f307-555c-4020-9609-4c6b6da3714b"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Books To Read/ML Engineering Notebook+Docs/mlops-cicd-lab'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["!mkdir src tests"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FoAM2x5XXngU","executionInfo":{"status":"ok","timestamp":1764517610493,"user_tz":-60,"elapsed":87,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"54266b46-5d3d-44e4-9f45-a6897646d7d4"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘src’: File exists\n","mkdir: cannot create directory ‘tests’: File exists\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J9rKOWWjXsrm","executionInfo":{"status":"ok","timestamp":1764517610629,"user_tz":-60,"elapsed":130,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"91f06234-eb27-46ef-87cc-58f9b54a174d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["requirements.txt  src  tests\n"]}]},{"cell_type":"code","source":["!touch src/__init__.py tests/__init__.py"],"metadata":{"id":"YnwKMjAXXtxo","executionInfo":{"status":"ok","timestamp":1764517610771,"user_tz":-60,"elapsed":139,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["**Step 2: Create a Logic File**\n","-\n","Create `src/preprocessing.py`. We will write a simple function that cleans data."],"metadata":{"id":"Ks11lelxX0-8"}},{"cell_type":"code","source":["%%writefile src/preprocessing.py\n","# src/preprocessing.py\n","import pandas as pd\n","\n","def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    Removes rows with missing values and resets index.\n","    \"\"\"\n","    df_clean = df.dropna().reset_index(drop=True)\n","    return df_clean\n","\n","def normalize_column(df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n","    \"\"\"Divides a column by its maximum value.\"\"\"\n","    # Avoid Division by Zero edge case in real life, but kept simple for now\n","    if df[col_name].max() != 0:\n","        df[col_name] = df[col_name] / df[col_name].max()\n","    return df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E-1Q2-HzXxa8","executionInfo":{"status":"ok","timestamp":1764517610775,"user_tz":-60,"elapsed":18,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"d8278960-657a-4b2d-db37-3620700e0dc9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting src/preprocessing.py\n"]}]},{"cell_type":"markdown","source":["**Step 3: Create a Test File**\n","-\n","Create `tests/test_preprocessing.py`. We will test if clean_data actually removes NaNs."],"metadata":{"id":"4tXzQmscZAi8"}},{"cell_type":"code","source":["%%writefile tests/test_preprocessing.py\n","# tests/test_preprocessing.py\n","import pandas as pd\n","import pytest\n","from src.preprocessing import clean_data, normalize_column\n","\n","def test_clean_data_removes_nulls():\n","    # 1. Arrange: Create dummy dirty data\n","    raw_data = pd.DataFrame({\n","        \"feature1\": [1.0, 2.0, None, 4.0],\n","        \"feature2\": [\"a\", \"b\", \"c\", None]\n","    })\n","\n","    # 2. Act: Apply the function\n","    clean_df = clean_data(raw_data)\n","\n","    # 3. Assert: Check expectations\n","    # We expect 2 rows to be removed (index 2 and 3)\n","    assert len(clean_df) == 2\n","    assert clean_df.isnull().sum().sum() == 0\n","\n","def test_normalize_column_max_is_one():\n","    # 1. Arrange\n","    df = pd.DataFrame({'test_col': [10, 20, 50, 25]})\n","\n","    # 2. Act\n","    df_norm = normalize_column(df, 'test_col')\n","\n","    # 3. Assert\n","    # The max value (50) should become 1.0\n","    assert df_norm['test_col'].max() == 1.0\n","    # The min value (10) should become 0.2\n","    assert df_norm['test_col'].min() == 0.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8QDxmfRJY45i","executionInfo":{"status":"ok","timestamp":1764517663409,"user_tz":-60,"elapsed":61,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"9821d0f8-6da4-49b5-d832-159671a3821d"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting tests/test_preprocessing.py\n"]}]},{"cell_type":"markdown","source":["**Step 4: Install Dependencies & Run**\n","-\n","You need pandas and pytest."],"metadata":{"id":"JCVf6d7gZXKc"}},{"cell_type":"code","source":["%%writefile requirements.txt\n","pandas\n","pytest"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UddoY2iyZQ4B","executionInfo":{"status":"ok","timestamp":1764517610840,"user_tz":-60,"elapsed":29,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"655879c0-266f-44b7-dac0-2e8dff08ef4e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting requirements.txt\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0pyqV5KPZlzZ","executionInfo":{"status":"ok","timestamp":1764517619564,"user_tz":-60,"elapsed":8732,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"4d3b7755-72af-4187-b5a5-7a814203832c"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (8.4.2)\n","Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n","Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->-r requirements.txt (line 2)) (2.3.0)\n","Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from pytest->-r requirements.txt (line 2)) (25.0)\n","Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->-r requirements.txt (line 2)) (1.6.0)\n","Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest->-r requirements.txt (line 2)) (2.19.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n"]}]},{"cell_type":"markdown","source":["run the test command:"],"metadata":{"id":"-WvKh-7kZv6Y"}},{"cell_type":"code","source":["!pytest"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yNBC3OJLZrIc","executionInfo":{"status":"ok","timestamp":1764517675004,"user_tz":-60,"elapsed":3265,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"f8c7e5c0-59f3-41ea-8250-4e80b51be446"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m============================= test session starts ==============================\u001b[0m\n","platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n","rootdir: /content/drive/MyDrive/Books To Read/ML Engineering Notebook+Docs/mlops-cicd-lab\n","plugins: langsmith-0.4.47, typeguard-4.4.4, anyio-4.11.0\n","collected 2 items                                                              \u001b[0m\n","\n","tests/test_preprocessing.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                           [100%]\u001b[0m\n","\n","\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.85s\u001b[0m\u001b[32m ===============================\u001b[0m\n"]}]},{"cell_type":"markdown","source":["# **The CI Pipeline (Continuous Integration)**\n","\n","**The Concept**:\n","\n","> CI (Continuous Integration) means: \"Every time I save/push code, a robot runs the tests for me.\"\n","If the robot says \"Fail,\" I am not allowed to merge the code.\n","\n","**Step 1: Git Initialization**\n","-\n","Initialize git in your folder:\n"],"metadata":{"id":"k6uuphLwc2Ds"}},{"cell_type":"code","source":["%pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"0QSBcdFdZykU","executionInfo":{"status":"ok","timestamp":1764517878510,"user_tz":-60,"elapsed":82,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"d912272d-53c4-402e-c021-774a7c039af5"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Books To Read/ML Engineering Notebook+Docs/mlops-cicd-lab'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["!git init"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZIDFk7Djdhfh","executionInfo":{"status":"ok","timestamp":1764517891837,"user_tz":-60,"elapsed":858,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"1ccd1c3d-ef21-47ca-a990-a132ca684e67"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n","\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n","\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n","\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit branch -m <name>\u001b[m\n","Initialized empty Git repository in /content/drive/MyDrive/Books To Read/ML Engineering Notebook+Docs/mlops-cicd-lab/.git/\n"]}]},{"cell_type":"markdown","source":["Create a .gitignore file (Crucial! Never push junk files):"],"metadata":{"id":"NeAhY4QqduQe"}},{"cell_type":"code","source":["!touch .gitignore"],"metadata":{"id":"SPaHhbYydkoX","executionInfo":{"status":"ok","timestamp":1764517934017,"user_tz":-60,"elapsed":217,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["Add this content to .gitignore:"],"metadata":{"id":"HNJ2d8RCdx5D"}},{"cell_type":"code","source":["%%writefile .gitignore\n","__pycache__/\n","*.pyc\n",".pytest_cache/\n",".ipynb_checkpoints/\n","venv/\n",".env\n","data/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8_R1eAKhdvF3","executionInfo":{"status":"ok","timestamp":1764517981922,"user_tz":-60,"elapsed":48,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"39e2ef65-a6ec-41ab-88cb-3efd1ad569e7"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting .gitignore\n"]}]},{"cell_type":"markdown","source":["**Step 2: Defining the GitHub Action**\n","-\n","GitHub looks for YAML files in `.github/workflows/`.\n","\n","Create the directory:"],"metadata":{"id":"wR2kmgV3d_-M"}},{"cell_type":"code","source":["!mkdir -p .github/workflows"],"metadata":{"id":"-FGbcNHhd6tx","executionInfo":{"status":"ok","timestamp":1764518066045,"user_tz":-60,"elapsed":94,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["Create a file named `ci-pipeline.yml`:"],"metadata":{"id":"lg0J6nSCeT0b"}},{"cell_type":"code","source":["!touch .github/workflows/ci-pipeline.yml"],"metadata":{"id":"8M3jwrKVePNo","executionInfo":{"status":"ok","timestamp":1764518100441,"user_tz":-60,"elapsed":176,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["**Step 3: Writing the Workflow**\n","-\n","Paste this into `ci-pipeline.yml`. This is your first Robot."],"metadata":{"id":"bgp1oaQUebJD"}},{"cell_type":"code","source":["%%writefile .github/workflows/ci-pipeline.yml\n","name: CI Pipeline\n","\n","# Trigger: Run this pipeline when code is pushed to the main branch\n","on:\n","  push:\n","    branches: [\"main\"]\n","  pull_request:\n","    branches: [\"main\"]\n","\n","# Job: The actual set of tasks\n","jobs:\n","  build-and-test:\n","    runs-on: ubuntu-latest  # The robot is a Virtual Machine (VM) running Linux\n","\n","    steps:\n","    # 1. Check out the code from the repo onto the VM\n","    - name: Checkout code\n","      uses: actions/checkout@v3\n","\n","    # 2. Install Python 3.9 on the VM\n","    - name: Set up Python\n","      uses: actions/setup-python@v4\n","      with:\n","        python-version: '3.9'\n","\n","    # 3. Install dependencies\n","    - name: Install dependencies\n","      run: |\n","        python -m pip install --upgrade pip\n","        pip install -r requirements.txt\n","\n","    # 4. Run the tests\n","    - name: Run Unit Tests\n","      run: pytest"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_mwfsidueXpD","executionInfo":{"status":"ok","timestamp":1764518302545,"user_tz":-60,"elapsed":87,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"4f7e3f22-0180-4df5-a5d7-3b7a868b53b4"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting .github/workflows/ci-pipeline.yml\n"]}]},{"cell_type":"markdown","source":["**Step 4: Activate the Robot**"],"metadata":{"id":"m8M7kjiYfSk2"}},{"cell_type":"markdown","source":["1. Create a **New Repository** on your GitHub account (name it mlops-cicd-lab).\n","\n","2. Push your local code to this remote repository:\n","```bash\n","git add .\n","git commit -m \"Initial commit with tests and CI pipeline\"\n","git branch -M main\n","git remote add origin https://github.com/<YOUR_USERNAME>/mlops-cicd-lab.git\n","git push -u origin main\n","```\n","\n","3. Go to your GitHub Repository page.\n","4. Click on the \"Actions\" tab."],"metadata":{"id":"0wvjr-w1fY-3"}},{"cell_type":"code","source":["%pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"hwXVpfM9g9Sp","executionInfo":{"status":"ok","timestamp":1764518784484,"user_tz":-60,"elapsed":53,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"c5660b99-4ae2-4df7-df06-ab291c9f1bdf"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Books To Read/ML Engineering Notebook+Docs/mlops-cicd-lab'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["!git add ."],"metadata":{"id":"HlsghA6WfIod","executionInfo":{"status":"ok","timestamp":1764518789313,"user_tz":-60,"elapsed":219,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RkEcyYA0hCP2","executionInfo":{"status":"ok","timestamp":1764518812639,"user_tz":-60,"elapsed":302,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"292723f6-8abd-41ae-c508-e94384f3ffd3"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch master\n","\n","No commits yet\n","\n","Changes to be committed:\n","  (use \"git rm --cached <file>...\" to unstage)\n","\t\u001b[32mnew file:   .github/workflows/ci-pipeline.yml\u001b[m\n","\t\u001b[32mnew file:   .gitignore\u001b[m\n","\t\u001b[32mnew file:   requirements.txt\u001b[m\n","\t\u001b[32mnew file:   src/__init__.py\u001b[m\n","\t\u001b[32mnew file:   src/preprocessing.py\u001b[m\n","\t\u001b[32mnew file:   tests/__init__.py\u001b[m\n","\t\u001b[32mnew file:   tests/test_preprocessing.py\u001b[m\n","\n"]}]},{"cell_type":"markdown","source":["Create a PAT token on GitHub:\n","- Go to: **GitHub** → **Settings** → **Developer settings** → **Personal access tokens** → **Fine-grained tokens**\n","- Create a token with permissions:\n","\n","1. Contents → Read & Write\n","2. Metadata → Read\n","3. Actions → Read & Write\n","4. Workflow → Read & Write"],"metadata":{"id":"5HVo2NCjsf2i"}},{"cell_type":"code","source":["from google.colab import userdata\n","EMAIL = userdata.get('EMAIL')\n","GITHUB_USER_NAME = userdata.get('GITHUB_USER_NAME')\n","TOKEN = userdata.get('GITHUB_TOKEN')\n","\n","GITHUB_USER_NAME"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"cIAaVXh-hs0w","executionInfo":{"status":"ok","timestamp":1764542052220,"user_tz":-60,"elapsed":2115,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"56317de2-5fcd-4f9a-bb1e-b428d0909b3f"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'mohamed-stifi'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["!git config --global user.email {EMAIL}\n","!git config --global user.name {GITHUB_USER_NAME}"],"metadata":{"id":"yi7ffCfvhZC5","executionInfo":{"status":"ok","timestamp":1764542054041,"user_tz":-60,"elapsed":201,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"Initial commit with tests and CI pipeline\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v875uYTdg_5k","executionInfo":{"status":"ok","timestamp":1764519082541,"user_tz":-60,"elapsed":783,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"1f6b3909-bc9e-4329-c6a0-83660169ea7f"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["[master (root-commit) 7791a0e] Initial commit with tests and CI pipeline\n"," 7 files changed, 91 insertions(+)\n"," create mode 100644 .github/workflows/ci-pipeline.yml\n"," create mode 100644 .gitignore\n"," create mode 100644 requirements.txt\n"," create mode 100644 src/__init__.py\n"," create mode 100644 src/preprocessing.py\n"," create mode 100644 tests/__init__.py\n"," create mode 100644 tests/test_preprocessing.py\n"]}]},{"cell_type":"code","source":["!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EMk56IPrhKb8","executionInfo":{"status":"ok","timestamp":1764521005336,"user_tz":-60,"elapsed":1533,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"e3a3ee1b-b1ef-4011-fafe-1d8fb9b6135b"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","nothing to commit, working tree clean\n"]}]},{"cell_type":"code","source":["!git branch -M main"],"metadata":{"id":"mbw7Y9SBhUaK","executionInfo":{"status":"ok","timestamp":1764519110303,"user_tz":-60,"elapsed":1370,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# !git remote add origin https://github.com/{GITHUB_USER_NAME}/mlops-cicd-lab.git\n","!git remote set-url origin https://{GITHUB_USER_NAME}:{TOKEN}@github.com/{GITHUB_USER_NAME}/mlops-cicd-lab.git"],"metadata":{"id":"xbQyFygpiNk7","executionInfo":{"status":"ok","timestamp":1764521172430,"user_tz":-60,"elapsed":54,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["#!git remote -v"],"metadata":{"id":"F9aItKx3jS2r","executionInfo":{"status":"ok","timestamp":1764521798887,"user_tz":-60,"elapsed":803,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["!git push -u origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HCCMk_sVid5m","executionInfo":{"status":"ok","timestamp":1764521574031,"user_tz":-60,"elapsed":2007,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"6ab9311c-f620-4751-9bbe-c74df5d67610"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 12, done.\n","Counting objects:   8% (1/12)\rCounting objects:  16% (2/12)\rCounting objects:  25% (3/12)\rCounting objects:  33% (4/12)\rCounting objects:  41% (5/12)\rCounting objects:  50% (6/12)\rCounting objects:  58% (7/12)\rCounting objects:  66% (8/12)\rCounting objects:  75% (9/12)\rCounting objects:  83% (10/12)\rCounting objects:  91% (11/12)\rCounting objects: 100% (12/12)\rCounting objects: 100% (12/12), done.\n","Delta compression using up to 2 threads\n","Compressing objects:  12% (1/8)\rCompressing objects:  25% (2/8)\rCompressing objects:  37% (3/8)\rCompressing objects:  50% (4/8)\rCompressing objects:  62% (5/8)\rCompressing objects:  75% (6/8)\rCompressing objects:  87% (7/8)\rCompressing objects: 100% (8/8)\rCompressing objects: 100% (8/8), done.\n","Writing objects:   8% (1/12)\rWriting objects:  16% (2/12)\rWriting objects:  25% (3/12)\rWriting objects:  33% (4/12)\rWriting objects:  41% (5/12)\rWriting objects:  50% (6/12)\rWriting objects:  58% (7/12)\rWriting objects:  66% (8/12)\rWriting objects:  75% (9/12)\rWriting objects:  83% (10/12)\rWriting objects:  91% (11/12)\rWriting objects: 100% (12/12)\rWriting objects: 100% (12/12), 1.86 KiB | 50.00 KiB/s, done.\n","Total 12 (delta 0), reused 0 (delta 0), pack-reused 0\n","To https://github.com/mohamed-stifi/mlops-cicd-lab.git\n"," * [new branch]      main -> main\n","Branch 'main' set up to track remote branch 'main' from 'origin'.\n"]}]},{"cell_type":"markdown","source":["# **CI for Machine Learning Logic**\n","> Right now, we are testing data cleaning functions. But as an ML Engineer, you need to test Model Training too.\n","\n","**Step 1: Define Dependencies Properly**\n","-\n","Update `requirements.txt` in the root folder:"],"metadata":{"id":"rXkayfEj1pFU"}},{"cell_type":"code","source":["%%writefile requirements.txt\n","pandas\n","pytest\n","scikit-learn\n","joblib"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MNEF6MPzijCD","executionInfo":{"status":"ok","timestamp":1764524366132,"user_tz":-60,"elapsed":127,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"4b723549-34b5-4bd0-ca48-11c5b9fd98ca"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting requirements.txt\n"]}]},{"cell_type":"markdown","source":["**Step 2: Create the Training Logic**\n","-\n","We will write a training function that fits a simple model. We design it as a function, not a script, so it's easy to test.\n","\n","Create `src/train.py`:"],"metadata":{"id":"cIbMWVCQ2VB-"}},{"cell_type":"code","source":["%%writefile src/train.py\n","# src/train.py\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import joblib\n","\n","def train_model(n_estimators: int = 100):\n","    \"\"\"Trains a Random Forest on the Iris dataset.\"\"\"\n","    # 1. Load Data\n","    iris = load_iris()\n","    X, y = iris.data, iris.target\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # 2. Train\n","    model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n","    model.fit(X_train, y_train)\n","\n","    # 3. Evaluate\n","    predictions = model.predict(X_test)\n","    accuracy = accuracy_score(y_test, predictions)\n","\n","    return model, accuracy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nUq40jyC2RcD","executionInfo":{"status":"ok","timestamp":1764524462810,"user_tz":-60,"elapsed":45,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"f19527b3-389b-42f5-c975-af520995b87d"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing src/train.py\n"]}]},{"cell_type":"markdown","source":["**Step 3: Test the Model Logic**\n","-\n","How do you unit test an ML model?\n","- **Smoke Test**: Does the function run without crashing?\n","- **Sanity Check**: Is accuracy better than random guessing? (> 0.33 for Iris)\n","- **Shape Check**: Does prediction output have the right shape?\n","\n","\n","Create `tests/test_train.py`:"],"metadata":{"id":"daQOL5V42s0V"}},{"cell_type":"code","source":["%%writefile tests/test_train.py\n","# tests/test_train.py\n","import pytest\n","from src.train import train_model\n","\n","def test_train_model_runs():\n","    \"\"\"Smoke test: Does training finish and return a valid model?\"\"\"\n","    model, accuracy = train_model(n_estimators=10) # Use small N for speed\n","\n","    assert accuracy > 0.5  # Iris is easy, accuracy should be high\n","    assert hasattr(model, \"predict\") # Check if it's a real model object"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ptozWbNQ2pCn","executionInfo":{"status":"ok","timestamp":1764524591780,"user_tz":-60,"elapsed":50,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"c13ece66-4eb8-44e7-abb6-9384bc92e55c"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing tests/test_train.py\n"]}]},{"cell_type":"markdown","source":["**Step 4: Test Check**\n","-\n","run"],"metadata":{"id":"WtrX0UlG3L3X"}},{"cell_type":"code","source":["!pytest"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9p1AjejF3Ije","executionInfo":{"status":"ok","timestamp":1764524724258,"user_tz":-60,"elapsed":11818,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"6789eced-958a-41dd-caf2-f7dfe3e8ec24"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m============================= test session starts ==============================\u001b[0m\n","platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n","rootdir: /content/drive/MyDrive/Books To Read/ML Engineering Notebook+Docs/mlops-cicd-lab\n","plugins: langsmith-0.4.47, typeguard-4.4.4, anyio-4.11.0\n","collected 3 items                                                              \u001b[0m\n","\n","tests/test_preprocessing.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                           [ 66%]\u001b[0m\n","tests/test_train.py \u001b[32m.\u001b[0m\u001b[32m                                                    [100%]\u001b[0m\n","\n","\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 7.19s\u001b[0m\u001b[32m ===============================\u001b[0m\n"]}]},{"cell_type":"markdown","source":["**Step 5: Push to GitHub**\n","-\n"],"metadata":{"id":"xanQMFCP3wFx"}},{"cell_type":"code","source":["!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3o7AWrBf37p0","executionInfo":{"status":"ok","timestamp":1764524810780,"user_tz":-60,"elapsed":269,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"87f116c4-d7d6-4a8c-9550-966673c08fa7"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   requirements.txt\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31msrc/train.py\u001b[m\n","\t\u001b[31mtests/test_train.py\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"code","source":["!git add ."],"metadata":{"id":"1cfGsnZO3l9f","executionInfo":{"status":"ok","timestamp":1764524814505,"user_tz":-60,"elapsed":394,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fDq3wvv3-1D","executionInfo":{"status":"ok","timestamp":1764524824998,"user_tz":-60,"elapsed":520,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"285dee52-cb64-400b-805b-69a3b1b341c4"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes to be committed:\n","  (use \"git restore --staged <file>...\" to unstage)\n","\t\u001b[32mmodified:   requirements.txt\u001b[m\n","\t\u001b[32mnew file:   src/train.py\u001b[m\n","\t\u001b[32mnew file:   tests/test_train.py\u001b[m\n","\n"]}]},{"cell_type":"code","source":["!git commit -m \"Add ML training logic and requirements\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1AB3PN984BWc","executionInfo":{"status":"ok","timestamp":1764524850884,"user_tz":-60,"elapsed":495,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"1abde34c-ee3f-4da7-8ce0-c62809666285"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["[main 7387cd1] Add ML training logic and requirements\n"," 3 files changed, 35 insertions(+)\n"," create mode 100644 src/train.py\n"," create mode 100644 tests/test_train.py\n"]}]},{"cell_type":"code","source":["!git push"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_EPlMtKp4HrQ","executionInfo":{"status":"ok","timestamp":1764524858602,"user_tz":-60,"elapsed":1659,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"959576f6-bdb8-4dd9-b8ed-e1929c33d21d"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 11, done.\n","Counting objects:   9% (1/11)\rCounting objects:  18% (2/11)\rCounting objects:  27% (3/11)\rCounting objects:  36% (4/11)\rCounting objects:  45% (5/11)\rCounting objects:  54% (6/11)\rCounting objects:  63% (7/11)\rCounting objects:  72% (8/11)\rCounting objects:  81% (9/11)\rCounting objects:  90% (10/11)\rCounting objects: 100% (11/11)\rCounting objects: 100% (11/11), done.\n","Delta compression using up to 2 threads\n","Compressing objects:  16% (1/6)\rCompressing objects:  33% (2/6)\rCompressing objects:  50% (3/6)\rCompressing objects:  66% (4/6)\rCompressing objects:  83% (5/6)\rCompressing objects: 100% (6/6)\rCompressing objects: 100% (6/6), done.\n","Writing objects:  14% (1/7)\rWriting objects:  28% (2/7)\rWriting objects:  42% (3/7)\rWriting objects:  57% (4/7)\rWriting objects:  71% (5/7)\rWriting objects:  85% (6/7)\rWriting objects: 100% (7/7)\rWriting objects: 100% (7/7), 1.26 KiB | 37.00 KiB/s, done.\n","Total 7 (delta 0), reused 0 (delta 0), pack-reused 0\n","To https://github.com/mohamed-stifi/mlops-cicd-lab.git\n","   7791a0e..7387cd1  main -> main\n"]}]},{"cell_type":"markdown","source":["# **Packaging & Containerization**\n","Now that our code is tested and \"CI-verified\", we need to ship it.\n","> We cannot email `src/train.py` to the production server. The server might have the wrong Python version or missing libraries.\n","\n","We use **Docker**.\n","\n","**Step 1: The Dockerfile**\n","-\n","\n","A `Dockerfile` is a recipe to build a computer that contains your project.\n","\n","Create a file named `Dockerfile` (no extension) in the root of `mlops-cicd-lab`.\n"],"metadata":{"id":"VJkLw8b87BpX"}},{"cell_type":"code","source":["%%writefile Dockerfile\n","# 1. Base Image: Start with a lightweight Linux + Python 3.9\n","FROM python:3.9-slim\n","\n","# 2. Setup Work Directory: Create a folder inside the container\n","WORKDIR /app\n","\n","# 3. Copy Requirements: Move the file from laptop to container\n","COPY requirements.txt .\n","\n","# 4. Install Dependencies: Run pip inside the container\n","# --no-cache-dir keeps the image small\n","RUN pip install --no-cache-dir -r requirements.txt\n","\n","# 5. Copy Code: Move the src folder\n","COPY src/ src/\n","\n","# 6. Default Command: What happens when we run the container?\n","# For now, let's make it run the training script\n","CMD [\"python\", \"-c\", \"from src.train import train_model; print(train_model())\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZ7IR0Y67BXV","executionInfo":{"status":"ok","timestamp":1764526338749,"user_tz":-60,"elapsed":72,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"472b6684-eb99-4237-a045-90f584e4809d"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing Dockerfile\n"]}]},{"cell_type":"markdown","source":["**Step 2: Build the Image**\n","-\n","This turns the recipe into an actual \"Image\" (a frozen computer).\n","\n","> Install Docker in your machine (if you use google colab like me follow this guide [install_docker_in_colab](https://gist.github.com/mwufi/6718b30761cd109f9aff04c5144eb885)\n",")\n","\n","Run this in your terminal:"],"metadata":{"id":"qd5Rf28C93PA"}},{"cell_type":"code","source":["# !docker build -t mlops-train:v1 ."],"metadata":{"id":"_jI0q4PKCJiB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 3: Run the Container**\n","-\n","Now we spin up a container from that image."],"metadata":{"id":"xTVCKYh9DJmM"}},{"cell_type":"code","source":["#!docker run mlops-train:v1"],"metadata":{"id":"r7jyRN1zB6TY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 4: Update Dockerfile**\n","-\n"],"metadata":{"id":"Av8UobNa4e9O"}},{"cell_type":"code","source":["%%writefile Dockerfile\n","# 1. Base Image: Start with a lightweight Linux + Python 3.9\n","FROM python:3.9-slim\n","\n","# 2. Setup Work Directory: Create a folder inside the container\n","WORKDIR /app\n","\n","# 3. Copy Requirements: Move the file from laptop to container\n","COPY requirements.txt .\n","\n","# 4. Install Dependencies: Run pip inside the container\n","# --no-cache-dir keeps the image small\n","RUN pip install --no-cache-dir -r requirements.txt\n","\n","# 5. Copy Code: Move the src folder\n","COPY src/ src/\n","COPY tests/ tests/\n","\n","# 6. Default Command: What happens when we run the container?\n","# For now, let's make it run the training script\n","CMD [\"python\", \"-c\", \"from src.train import train_model; print(train_model())\"]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQ-PpYkc4isP","executionInfo":{"status":"ok","timestamp":1764541865747,"user_tz":-60,"elapsed":150,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"4229efd1-8799-411b-e772-f8f943c9f41d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting Dockerfile\n"]}]},{"cell_type":"code","source":["!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pmvZwsxPtyNT","executionInfo":{"status":"ok","timestamp":1764538936163,"user_tz":-60,"elapsed":12381,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"ad088dda-11d3-4608-86ae-71a28b19ab4f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Refresh index: 100% (9/9), done.\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31mDockerfile\u001b[m\n","\n","nothing added to commit but untracked files present (use \"git add\" to track)\n"]}]},{"cell_type":"markdown","source":["# **Automating the Build (CD - Continuous Delivery)**\n","\n","> Manual docker build is for experimentation. In production, GitHub Actions should build the image and push it to a `Registry` (like an App Store for Docker images).\n","\n","We will use **Docker Hub** (it's free and standard).\n","\n","**Step 1: Setup Docker Hub**\n","-\n","1. Go to [`hub.docker.com`](hub.docker.com) and create a free account (if you don't have one).\n","2. Create a **New Repository**:\n","- Name: mlops-cicd\n","- Visibility: Public (easier for learning, keeps it free).\n","\n","**Step 2: Connect GitHub to Docker Hub**\n","-\n","Your GitHub robot needs permission to upload files to your Docker Hub account. We use **Secrets**\n","\n","1. Go to your GitHub Repo → Settings → Secrets and variables → Actions.\n","2. Click New repository secret.\n","3. Add two secrets:\n","- **DOCKER_USERNAME**: Your Docker Hub ID.\n","- **DOCKER_PASSWORD**: Your Docker Hub Password (or an Access Token, which is better, but password works for now).\n","\n","**Step 3: Update the Pipeline**\n","-\n","We are going to modify `.github/workflows/ci-pipeline.yml`.\n","\n","We will add a new **job** called `build-and-push-image`.\n","\n","**Logic:**\n","1. Run Tests first.\n","2. **IF** tests pass → Log in to Docker Hub → Build Image → Push Image.\n","\n","Replace your entire YAML file with this advanced version:"],"metadata":{"id":"6ipzwAonxeFt"}},{"cell_type":"code","source":["%%writefile .github/workflows/ci-pipeline.yml\n","name: CI/CD Pipeline\n","\n","on:\n","  push:\n","    branches: [\"main\"]\n","\n","jobs:\n","  # Job 1: The CI Part (Testing)\n","  test:\n","    runs-on: ubuntu-latest\n","    steps:\n","    - uses: actions/checkout@v3\n","    - name: Set up Python\n","      uses: actions/setup-python@v4\n","      with:\n","        python-version: '3.9'\n","    - name: Install dependencies\n","      run: |\n","        python -m pip install --upgrade pip\n","        pip install -r requirements.txt\n","    - name: Run Unit Tests\n","      run: pytest\n","\n","  # Job 2: The CD Part (Building & Delivering)\n","  build-image:\n","    needs: test  # <--- CRITICAL: Only run if 'test' passes!\n","    runs-on: ubuntu-latest\n","    steps:\n","      - name: Checkout code\n","        uses: actions/checkout@v3\n","\n","      - name: Log in to Docker Hub\n","        uses: docker/login-action@v2\n","        with:\n","          username: ${{ secrets.DOCKER_USERNAME }}\n","          password: ${{ secrets.DOCKER_PASSWORD }}\n","\n","      - name: Build and push Docker image\n","        uses: docker/build-push-action@v4\n","        with:\n","          context: .\n","          push: true\n","          # Change 'your-username' below to your actual Docker Hub username!\n","          tags: ${{ secrets.DOCKER_USERNAME }}/mlops-cicd:latest"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WNGYm3r-tzk5","executionInfo":{"status":"ok","timestamp":1764541680432,"user_tz":-60,"elapsed":72,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"ef24222a-d2ee-4772-de13-db93479e5e50"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting .github/workflows/ci-pipeline.yml\n"]}]},{"cell_type":"code","source":["!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQg7g2yX4Uew","executionInfo":{"status":"ok","timestamp":1764541891851,"user_tz":-60,"elapsed":269,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"161ef9af-e244-4843-fb07-c5b617b6f122"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   .github/workflows/ci-pipeline.yml\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31mDockerfile\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"code","source":["!git add ."],"metadata":{"id":"OjhGVSM45IJh","executionInfo":{"status":"ok","timestamp":1764541907883,"user_tz":-60,"elapsed":25,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JU44pZkC5ME1","executionInfo":{"status":"ok","timestamp":1764541924944,"user_tz":-60,"elapsed":3342,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"894f648e-6721-4e33-9817-ba4cb4deeb89"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes to be committed:\n","  (use \"git restore --staged <file>...\" to unstage)\n","\t\u001b[32mmodified:   .github/workflows/ci-pipeline.yml\u001b[m\n","\t\u001b[32mnew file:   Dockerfile\u001b[m\n","\n"]}]},{"cell_type":"code","source":["!git commit -m \"Add Docker Containerization and CD Job\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fb8jR2JY5PXt","executionInfo":{"status":"ok","timestamp":1764542073403,"user_tz":-60,"elapsed":3527,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"c47c47cf-3d07-4588-f354-73b352e4aefd"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[main f28fe4b] Add Docker Containerization and CD Job\n"," 2 files changed, 47 insertions(+), 17 deletions(-)\n"," create mode 100644 Dockerfile\n"]}]},{"cell_type":"code","source":["!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-a5a44FH5mFw","executionInfo":{"status":"ok","timestamp":1764542118818,"user_tz":-60,"elapsed":518,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"6ccf961e-1a92-46cc-954a-1cce05f6307f"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is ahead of 'origin/main' by 1 commit.\n","  (use \"git push\" to publish your local commits)\n","\n","nothing to commit, working tree clean\n"]}]},{"cell_type":"code","source":["!git push"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wbgp45i159cM","executionInfo":{"status":"ok","timestamp":1764542137488,"user_tz":-60,"elapsed":4259,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"8511d7d7-c971-4b29-9b71-dfdec79341ae"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 10, done.\n","Counting objects:  10% (1/10)\rCounting objects:  20% (2/10)\rCounting objects:  30% (3/10)\rCounting objects:  40% (4/10)\rCounting objects:  50% (5/10)\rCounting objects:  60% (6/10)\rCounting objects:  70% (7/10)\rCounting objects:  80% (8/10)\rCounting objects:  90% (9/10)\rCounting objects: 100% (10/10)\rCounting objects: 100% (10/10), done.\n","Delta compression using up to 2 threads\n","Compressing objects:  25% (1/4)\rCompressing objects:  50% (2/4)\rCompressing objects:  75% (3/4)\rCompressing objects: 100% (4/4)\rCompressing objects: 100% (4/4), done.\n","Writing objects:  16% (1/6)\rWriting objects:  33% (2/6)\rWriting objects:  50% (3/6)\rWriting objects:  66% (4/6)\rWriting objects:  83% (5/6)\rWriting objects: 100% (6/6)\rWriting objects: 100% (6/6), 1.43 KiB | 69.00 KiB/s, done.\n","Total 6 (delta 0), reused 0 (delta 0), pack-reused 0\n","To https://github.com/mohamed-stifi/mlops-cicd-lab.git\n","   7387cd1..f28fe4b  main -> main\n"]}]},{"cell_type":"markdown","source":["# **The CD Pipeline (FastAPI Serving)**\n","\n","Right now, your Docker image just runs a script and exits. That is useful for Batch Training, but useless for a Real-time App (like a website asking for a prediction).\n","\n","> We need to wrap our model in a **REST API**. We will use `FastAPI`, the modern standard for Python ML serving.\n","\n","**Step 1: Save the Model Artifact**\n","-\n","An API needs a trained model file (`model.joblib`) to load.\n","\n","Modify `src/train.py` to **save** the model to disk after training."],"metadata":{"id":"0lZA9zG59Jbu"}},{"cell_type":"code","source":["%%writefile src/train.py\n","# src/train.py (Updated)\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import joblib\n","\n","def train_model(n_estimators: int = 100):\n","    iris = load_iris()\n","    X, y = iris.data, iris.target\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n","    model.fit(X_train, y_train)\n","\n","    predictions = model.predict(X_test)\n","    accuracy = accuracy_score(y_test, predictions)\n","\n","    # --- NEW: Save the model ---\n","    joblib.dump(model, \"model.joblib\")\n","    print(f\"Model saved to model.joblib with accuracy: {accuracy}\")\n","\n","    return model, accuracy\n","\n","if __name__ == \"__main__\":\n","    train_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EmZ7Cm-r6CBS","executionInfo":{"status":"ok","timestamp":1764543194743,"user_tz":-60,"elapsed":118,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"8340526f-2b3f-4363-e185-6f0eacae90dd"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting src/train.py\n"]}]},{"cell_type":"markdown","source":["**Step 2: Create the API**\n","-\n","Create a new file `src/app.py`. This script will:\n","\n","1. Load the saved model.\n","2. Listen for HTTP requests.\n","3. Return predictions."],"metadata":{"id":"bHn1ih-g-J4W"}},{"cell_type":"code","source":["%%writefile src/app.py\n","# src/app.py\n","from fastapi import FastAPI\n","from pydantic import BaseModel\n","import joblib\n","import numpy as np\n","\n","# 1. Define Input Schema (Data Validation)\n","class IrisInput(BaseModel):\n","    sepal_length: float\n","    sepal_width: float\n","    petal_length: float\n","    petal_width: float\n","\n","# 2. Load Model\n","app = FastAPI(title=\"Iris Prediction API\")\n","model = joblib.load(\"model.joblib\")\n","\n","# 3. Define Endpoint\n","@app.post(\"/predict\")\n","def predict(data: IrisInput):\n","    # Convert input to numpy array\n","    features = np.array([[\n","        data.sepal_length,\n","        data.sepal_width,\n","        data.petal_length,\n","        data.petal_width\n","    ]])\n","\n","    # Make prediction\n","    prediction = model.predict(features)\n","    return {\"class\": int(prediction[0])}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6hI7Y05W-GMh","executionInfo":{"status":"ok","timestamp":1764543343072,"user_tz":-60,"elapsed":107,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"72176709-fd88-44b1-aca1-3df26f27f9bc"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing src/app.py\n"]}]},{"cell_type":"markdown","source":["**Step 3: Update Requirements**\n","-\n","Add these to `requirements.txt`:\n","- fastapi\n","- uvicorn"],"metadata":{"id":"r1kanErO-uET"}},{"cell_type":"code","source":["%%writefile requirements.txt\n","pandas\n","pytest\n","scikit-learn\n","joblib\n","fastapi\n","uvicorn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oj9IzkvQ-qeA","executionInfo":{"status":"ok","timestamp":1764543560717,"user_tz":-60,"elapsed":12,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"adc5564c-c962-4c9e-fa56-72861050a611"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting requirements.txt\n"]}]},{"cell_type":"markdown","source":["**Step 4: Update Dockerfile (The \"Serving\" Image)**\n","-\n","We need to change the `Dockerfile` to:\n","1. Run the training script during the build (so `model.joblib` exists inside the image).\n","2. Start the Web Server (`uvicorn`) instead of running a script.\n","\n","Update your `Dockerfile`:"],"metadata":{"id":"UkmPIwr1_Huu"}},{"cell_type":"code","source":["%%writefile Dockerfile\n","FROM python:3.9-slim\n","\n","WORKDIR /app\n","\n","COPY requirements.txt .\n","RUN pip install --no-cache-dir -r requirements.txt\n","\n","COPY src/ src/\n","COPY tests/ tests/\n","\n","# 1. Build-Time Training: Train the model so it is baked into the image\n","# (In advanced MLOps, we download from S3/MLflow, but this is best for starting)\n","RUN python src/train.py\n","\n","# 2. Expose the port (Documentation only)\n","EXPOSE 8000\n","\n","# 3. Run the API Server\n","CMD [\"uvicorn\", \"src.app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0jv5lb0l_G3V","executionInfo":{"status":"ok","timestamp":1764543667061,"user_tz":-60,"elapsed":34,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"2cb03cf8-30ee-4f9c-922b-a87cee9b8613"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting Dockerfile\n"]}]},{"cell_type":"markdown","source":["**Rebuild locally**:"],"metadata":{"id":"k5gOlkxYAA3S"}},{"cell_type":"code","source":["#!docker build -t mlops-api:v1 ."],"metadata":{"id":"KuKKBaWa_5Y7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Run the API**:"],"metadata":{"id":"USlqBnX8AG2j"}},{"cell_type":"code","source":["#!docker run -p 8000:8000 mlops-api:v1"],"metadata":{"id":"dpeBmiT_AGpH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Test it**: Open your browser to: `http://localhost:8000/docs`.\n","\n","- This is the Swagger UI (Auto-generated by FastAPI).\n","- Click POST /predict → Try it out.\n","- Enter some numbers (e.g., 5.1, 3.5, 1.4, 0.2).\n","- Click Execute."],"metadata":{"id":"YtGkVHP3ARcM"}},{"cell_type":"markdown","source":["**Push to Github**"],"metadata":{"id":"CXTO9tLbAiof"}},{"cell_type":"code","source":["!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NdOJwb9RAWcb","executionInfo":{"status":"ok","timestamp":1764543867579,"user_tz":-60,"elapsed":36,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"f9bf4661-b007-4fa8-973f-bd9c82a84d6e"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   Dockerfile\u001b[m\n","\t\u001b[31mmodified:   requirements.txt\u001b[m\n","\t\u001b[31mmodified:   src/train.py\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31msrc/app.py\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"code","source":["!git add ."],"metadata":{"id":"zppqt8BeAqg9","executionInfo":{"status":"ok","timestamp":1764543878946,"user_tz":-60,"elapsed":315,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"FastAPI Serving\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XgHzl1wEAtP8","executionInfo":{"status":"ok","timestamp":1764543949837,"user_tz":-60,"elapsed":1638,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"2c5a0635-2417-4bf5-b2b7-ee59093b2c75"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["[main 64dc141] FastAPI Serving\n"," 4 files changed, 60 insertions(+), 25 deletions(-)\n"," rewrite Dockerfile (80%)\n"," create mode 100644 src/app.py\n"]}]},{"cell_type":"code","source":["!git push"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ry3gZct_A-NT","executionInfo":{"status":"ok","timestamp":1764543959351,"user_tz":-60,"elapsed":1332,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"9f1f7798-bd23-4f3e-ff48-7306c734cef0"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 12, done.\n","Counting objects:   8% (1/12)\rCounting objects:  16% (2/12)\rCounting objects:  25% (3/12)\rCounting objects:  33% (4/12)\rCounting objects:  41% (5/12)\rCounting objects:  50% (6/12)\rCounting objects:  58% (7/12)\rCounting objects:  66% (8/12)\rCounting objects:  75% (9/12)\rCounting objects:  83% (10/12)\rCounting objects:  91% (11/12)\rCounting objects: 100% (12/12)\rCounting objects: 100% (12/12), done.\n","Delta compression using up to 2 threads\n","Compressing objects:  14% (1/7)\rCompressing objects:  28% (2/7)\rCompressing objects:  42% (3/7)\rCompressing objects:  57% (4/7)\rCompressing objects:  71% (5/7)\rCompressing objects:  85% (6/7)\rCompressing objects: 100% (7/7)\rCompressing objects: 100% (7/7), done.\n","Writing objects:  14% (1/7)\rWriting objects:  28% (2/7)\rWriting objects:  42% (3/7)\rWriting objects:  57% (4/7)\rWriting objects:  71% (5/7)\rWriting objects:  85% (6/7)\rWriting objects: 100% (7/7)\rWriting objects: 100% (7/7), 1.49 KiB | 101.00 KiB/s, done.\n","Total 7 (delta 1), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n","To https://github.com/mohamed-stifi/mlops-cicd-lab.git\n","   f28fe4b..64dc141  main -> main\n"]}]},{"cell_type":"markdown","source":["# **The \"CT\" Pipeline (Continuous Training)**\n","The Flaw: currently, your `Dockerfile` has this line:\n","- `RUN python src/train.py`\n","\n","This means every time you build the image (even just to fix a typo in the README), the model retrains. This is wasteful and dangerous in production.\n","\n","> **The Solution**: We must decouple Training from Deployment.\n","\n","1. **CI Pipeline**: Checks code quality. (Fast).\n","2. **CT Pipeline**: Retrains the model. (Slow, triggered manually or by schedule).\n","\n","We will create a new workflow that uses G**itHub Artifacts** to pass the model between jobs.\n","\n","**Step 1: Clean the Dockerfile**\n","-\n","We will stop training inside the Docker build. The Docker image should just receive a pre-trained model.\n","\n","Remove the RUN python src/train.py line."],"metadata":{"id":"GmZfmtEJDpNZ"}},{"cell_type":"code","source":["%%writefile Dockerfile\n","FROM python:3.9-slim\n","\n","WORKDIR /app\n","\n","COPY requirements.txt .\n","RUN pip install --no-cache-dir -r requirements.txt\n","\n","COPY src/ src/\n","# COPY tests/ tests/  <-- In prod, we usually don't copy tests, but okay for lab.\n","\n","# ❌ REMOVED: RUN python src/train.py\n","# The model.joblib must be provided from the outside now!\n","\n","EXPOSE 8000\n","CMD [\"uvicorn\", \"src.app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kbaU2TeaBAn4","executionInfo":{"status":"ok","timestamp":1764544977686,"user_tz":-60,"elapsed":49,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"06685d2c-6f6e-47e6-8a2c-c4064b2276a8"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting Dockerfile\n"]}]},{"cell_type":"markdown","source":["**Step 2: Create the CT Workflow**\n","-\n","We will create a new file `.github/workflows/retrain.yml`.\n","\n","This workflow will utilize **Workflow Dispatch** (a manual button in GitHub) so you can trigger training on demand.\n","\n","**Logic:**\n","1. **Train Job**: Runs `src/train.py` and saves `model.joblib`. Uploads it as a temporary GitHub Artifact.\n","2. **Build Job**: Downloads the artifact, puts it in the folder, and then builds the Docker image.\n","\n","Create `.github/workflows/retrain.yml`:\n"],"metadata":{"id":"Za_-x8XQE9A3"}},{"cell_type":"code","source":["%%writefile .github/workflows/retrain.yml\n","name: Manual Retrain & Deploy\n","\n","# Trigger: Manual button click (or Schedule)\n","on:\n","  workflow_dispatch:\n","    inputs:\n","      n_estimators:\n","        description: 'Number of trees'\n","        required: true\n","        default: '150'\n","\n","jobs:\n","  # Job 1: Train the Model\n","  train:\n","    runs-on: ubuntu-latest\n","    steps:\n","    - uses: actions/checkout@v3\n","\n","    - name: Set up Python\n","      uses: actions/setup-python@v4\n","      with:\n","        python-version: '3.9'\n","\n","    - name: Install dependencies\n","      run: pip install -r requirements.txt\n","\n","    - name: Train Model\n","      # We pass the input from the UI to the script arguments\n","      run: |\n","        # We need to quickly modify train.py to accept args or just run default\n","        # For this lab, let's just run the script, assuming it saves model.joblib\n","        python src/train.py\n","\n","    - name: Upload Model Artifact\n","      uses: actions/upload-artifact@v4\n","      with:\n","        name: trained-model\n","        path: model.joblib\n","        retention-days: 1\n","\n","  # Job 2: Package & Push\n","  deploy:\n","    needs: train # Wait for training to finish\n","    runs-on: ubuntu-latest\n","    steps:\n","      - uses: actions/checkout@v3\n","\n","      - name: Download Model Artifact\n","        uses: actions/download-artifact@v4\n","        with:\n","          name: trained-model\n","          # Downloads to current directory, so Dockerfile finds it!\n","\n","      - name: Log in to Docker Hub\n","        uses: docker/login-action@v2\n","        with:\n","          username: ${{ secrets.DOCKER_USERNAME }}\n","          password: ${{ secrets.DOCKER_PASSWORD }}\n","\n","      - name: Build and push Docker image\n","        uses: docker/build-push-action@v4\n","        with:\n","          context: .\n","          push: true\n","          tags: ${{ secrets.DOCKER_USERNAME }}/mlops-cicd:prod"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mg7KDR5WE5j3","executionInfo":{"status":"ok","timestamp":1764546890471,"user_tz":-60,"elapsed":121,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"11fc21af-5d88-4ccc-f0d9-e6cea81ae3cd"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing .github/workflows/retrain.yml\n"]}]},{"cell_type":"markdown","source":["**Step 3: Push to GitHub**\n","-"],"metadata":{"id":"CpcD4SNhMZwQ"}},{"cell_type":"code","source":["!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"427rmEGdMMh7","executionInfo":{"status":"ok","timestamp":1764546969350,"user_tz":-60,"elapsed":67,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"d109c69b-4dce-4837-a1b5-8fa7001a1113"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   Dockerfile\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31m.github/workflows/retrain.yml\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"code","source":["!git add ."],"metadata":{"id":"lYNADQp2Mfw2","executionInfo":{"status":"ok","timestamp":1764546980949,"user_tz":-60,"elapsed":201,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"Add Continuous Training\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XAoyh0FlMiid","executionInfo":{"status":"ok","timestamp":1764547009365,"user_tz":-60,"elapsed":434,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"859250cc-eb95-4389-c32d-5983b9219c2f"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["[main 2289358] Add Continuous Training\n"," 2 files changed, 68 insertions(+), 7 deletions(-)\n"," create mode 100644 .github/workflows/retrain.yml\n"]}]},{"cell_type":"code","source":["!git push"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WOP1McWnMpej","executionInfo":{"status":"ok","timestamp":1764547017576,"user_tz":-60,"elapsed":1362,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"26fcca89-2204-43ea-cc9f-5770e7f305d8"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 10, done.\n","Counting objects:  10% (1/10)\rCounting objects:  20% (2/10)\rCounting objects:  30% (3/10)\rCounting objects:  40% (4/10)\rCounting objects:  50% (5/10)\rCounting objects:  60% (6/10)\rCounting objects:  70% (7/10)\rCounting objects:  80% (8/10)\rCounting objects:  90% (9/10)\rCounting objects: 100% (10/10)\rCounting objects: 100% (10/10), done.\n","Delta compression using up to 2 threads\n","Compressing objects:  20% (1/5)\rCompressing objects:  40% (2/5)\rCompressing objects:  60% (3/5)\rCompressing objects:  80% (4/5)\rCompressing objects: 100% (5/5)\rCompressing objects: 100% (5/5), done.\n","Writing objects:  16% (1/6)\rWriting objects:  33% (2/6)\rWriting objects:  50% (3/6)\rWriting objects:  66% (4/6)\rWriting objects:  83% (5/6)\rWriting objects: 100% (6/6)\rWriting objects: 100% (6/6), 1.43 KiB | 39.00 KiB/s, done.\n","Total 6 (delta 1), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n","To https://github.com/mohamed-stifi/mlops-cicd-lab.git\n","   64dc141..2289358  main -> main\n"]}]},{"cell_type":"markdown","source":["# **Documentation**\n","\n"],"metadata":{"id":"HlXAZMZhQJ35"}},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eSUfopxrQj5O","executionInfo":{"status":"ok","timestamp":1764548037160,"user_tz":-60,"elapsed":72,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"72c79a6f-ed51-4d6f-96c4-6260a2e3502e"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Dockerfile  docs  requirements.txt  src  tests\n"]}]},{"cell_type":"code","source":["import os\n","\n","# Create the docs directory\n","!mkdir -p docs\n","\n","# Verify\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yTbWagObMrOQ","executionInfo":{"status":"ok","timestamp":1764548108796,"user_tz":-60,"elapsed":235,"user":{"displayName":"mohamed stifi","userId":"01611456313962109710"}},"outputId":"98fdd741-dc41-4ad3-bde2-3d4930897edb"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Dockerfile  docs  requirements.txt  src  tests\n"]}]},{"cell_type":"markdown","source":["**Generate the README.md**\n","-"],"metadata":{"id":"yYFZhNq_Q9bP"}},{"cell_type":"code","source":["%%writefile README.md\n","# 🚀 MLOps CI/CD Lab: End-to-End Pipeline\n","\n","This repository demonstrates a production-grade **MLOps (Machine Learning Operations)** pipeline implemented using **GitHub Actions**, **Docker**, and **FastAPI**.\n","\n","It moves beyond simple model training scripts to a structured, automated ecosystem that ensures code quality, reproducibility, and automated deployment.\n","\n","## 🏗️ Architecture\n","\n","The system is designed with a **Separation of Concerns** principle:\n","\n","1.  **CI (Continuous Integration):** Triggered on every code push. verifying the code logic via Unit Tests.\n","2.  **CD (Continuous Delivery):** Packages the model and API into a Docker container and pushes it to Docker Hub.\n","3.  **CT (Continuous Training):** A decoupled workflow triggered manually (or via schedule) to retrain the model on heavy compute, completely separate from the deployment logic.\n","\n","---\n","\n","## 📂 Project Structure\n","\n","```text\n","mlops-cicd-lab/\n","├── .github/workflows/\n","│   ├── ci-pipeline.yml    # CI/CD: Tests code & Builds Docker image (if tests pass)\n","│   └── retrain.yml        # CT: Retrains model & Updates artifact (Manual Trigger)\n","├── docs/                  # Project documentation and tutorials\n","├── src/\n","│   ├── app.py             # FastAPI serving application\n","│   ├── train.py           # Model training logic (produces model.joblib)\n","│   └── preprocessing.py   # Data cleaning logic\n","├── tests/                 # Pytest unit tests\n","├── Dockerfile             # Recipe for the production image\n","├── requirements.txt       # Python dependencies\n","└── README.md              # Project documentation\n","```\n","---\n","\n","## ⚙️ Workflows Explained\n","\n","### 1. The Gatekeeper (CI Pipeline)\n","*   **Trigger:** `git push` to `main`.\n","*   **Action:** Installs dependencies and runs `pytest`.\n","*   **Goal:** Ensures no broken code (syntax errors, logic bugs) ever reaches the deployment stage.\n","\n","### 2. The Delivery Truck (CD Pipeline)\n","*   **Trigger:** Successful completion of the CI Tests.\n","*   **Action:**\n","    1.  Logs into Docker Hub using GitHub Secrets.\n","    2.  Builds a Docker image containing the code and the model.\n","    3.  Pushes the image to Docker Hub with the `latest` tag.\n","\n","### 3. The Factory (CT Pipeline)\n","*   **Trigger:** Manual \"Workflow Dispatch\" (UI Button).\n","*   **Action:**\n","    1.  Runs `src/train.py` to generate a new `model.joblib`.\n","    2.  Uploads the model as a GitHub Artifact.\n","    3.  Triggers the build process to package this **new** model into the Docker image.\n","*   **Why?** This decouples heavy training (which might need GPUs) from the lightweight CI checks.\n","\n","---\n","## 🚀 How to Run Locally\n","\n","### Prerequisites\n","*   Python 3.9+\n","*   Docker\n","\n","### 1. Installation\n","```bash\n","pip install -r requirements.txt\n","```\n","\n","### 2. Run Tests\n","```bash\n","pytest\n","```\n","\n","### 3. Build & Run Docker Container\n","```bash\n","# Build the image\n","docker build -t mlops-api:v1 .\n","\n","# Run the container (Mapping port 8000)\n","docker run -p 8000:8000 mlops-api:v1\n","```\n","\n","### 4. Test the API\n","Once the container is running, open your browser to the Swagger UI:\n","> `http://localhost:8000/docs`\n","\n","Or use curl:\n","```bash\n","curl -X 'POST' \\\n","  'http://localhost:8000/predict' \\\n","  -H 'Content-Type: application/json' \\\n","  -d '{\n","  \"sepal_length\": 5.1,\n","  \"sepal_width\": 3.5,\n","  \"petal_length\": 1.4,\n","  \"petal_width\": 0.2\n","}'\n","```\n","\n","---\n","## 🛠️ Technologies Used\n","\n","*   **GitHub Actions:** For orchestration.\n","*   **Docker:** For containerization and environment consistency.\n","*   **FastAPI:** For high-performance model serving.\n","*   **Scikit-Learn:** For the ML model (Random Forest).\n","*   **Pytest:** For automated testing.\n","*   **Docker Hub:** As the Container Registry.\n","\n","---\n","### 📖 Documentation\n","\n","A full step-by-step notebook explaining the creation of this pipeline can be found in `docs/project_documentation.ipynb`."],"metadata":{"id":"wMv9v3xSQ9HI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","### **Step 3: Push Changes to GitHub**\n","\n","Run these commands to commit the new structure and the documentation.\n","\n","```python\n","!git add .\n","!git commit -m \"Docs: Add README and move notebook to docs folder\"\n","!git push\n","```"],"metadata":{"id":"m-rOZtMAQhHA"},"execution_count":null,"outputs":[]}]}